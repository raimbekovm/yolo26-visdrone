{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO26 vs YOLO11 Benchmark on VisDrone\n",
    "\n",
    "Independent verification of Ultralytics YOLO26 claims:\n",
    "- **43% faster CPU inference** (ONNX)\n",
    "- **Better small object detection** (ProgLoss + STAL)\n",
    "- **NMS-free end-to-end inference**\n",
    "\n",
    "Dataset: VisDrone2019-DET (~90% small objects)\n",
    "\n",
    "Author: [Murat Raimbekov](https://github.com/raimbekovm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics>=8.4.0 pycocotools onnx onnxruntime onnxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'epochs': 50,\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'data': 'VisDrone.yaml',\n",
    "    'device': 0,\n",
    "    'workers': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "YOLO26_WEIGHTS = 'runs/yolo26n/weights/best.pt'\n\nif os.path.exists(YOLO26_WEIGHTS):\n    print(f\"Weights exist: {YOLO26_WEIGHTS}, skipping training\")\nelse:\n    yolo26 = YOLO('yolo26n.pt')\n    yolo26.train(\n        data=CONFIG['data'],\n        epochs=CONFIG['epochs'],\n        batch=CONFIG['batch'],\n        imgsz=CONFIG['imgsz'],\n        device=CONFIG['device'],\n        workers=CONFIG['workers'],\n        project='runs',\n        name='yolo26n',\n        exist_ok=True,\n    )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "YOLO11_WEIGHTS = 'runs/yolo11n/weights/best.pt'\n\nif os.path.exists(YOLO11_WEIGHTS):\n    print(f\"Weights exist: {YOLO11_WEIGHTS}, skipping training\")\nelse:\n    yolo11 = YOLO('yolo11n.pt')\n    yolo11.train(\n        data=CONFIG['data'],\n        epochs=CONFIG['epochs'],\n        batch=CONFIG['batch'],\n        imgsz=CONFIG['imgsz'],\n        device=CONFIG['device'],\n        workers=CONFIG['workers'],\n        project='runs',\n        name='yolo11n',\n        exist_ok=True,\n    )"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "yolo26_trained = YOLO(YOLO26_WEIGHTS)\nyolo11_trained = YOLO(YOLO11_WEIGHTS)\n\ndef get_model_info(model):\n    n_params = sum(p.numel() for p in model.model.parameters())\n    n_layers = len(list(model.model.modules()))\n    return n_params, n_layers\n\nparams26, layers26 = get_model_info(yolo26_trained)\nparams11, layers11 = get_model_info(yolo11_trained)\nprint(f\"YOLO26n: {params26/1e6:.2f}M params, {layers26} layers\")\nprint(f\"YOLO11n: {params11/1e6:.2f}M params, {layers11} layers\")\n\nval26 = yolo26_trained.val(data=CONFIG['data'], imgsz=CONFIG['imgsz'], device=CONFIG['device'])\nval11 = yolo11_trained.val(data=CONFIG['data'], imgsz=CONFIG['imgsz'], device=CONFIG['device'])\n\nmetrics = pd.DataFrame({\n    'Model': ['YOLO26n', 'YOLO11n'],\n    'Params_M': [params26/1e6, params11/1e6],\n    'mAP50': [val26.box.map50, val11.box.map50],\n    'mAP50-95': [val26.box.map, val11.box.map],\n    'Precision': [val26.box.mp, val11.box.mp],\n    'Recall': [val26.box.mr, val11.box.mr],\n})\nmetrics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Benchmark\n",
    "\n",
    "Ultralytics benchmarks CPU speed using ONNX format. We test both GPU (PyTorch) and CPU (ONNX)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_gpu(model, warmup=50, runs=200, imgsz=640):\n",
    "    dummy = np.random.randint(0, 255, (imgsz, imgsz, 3), dtype=np.uint8)\n",
    "    for _ in range(warmup):\n",
    "        model.predict(dummy, device=0, verbose=False)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        t0 = time.perf_counter()\n",
    "        model.predict(dummy, device=0, verbose=False)\n",
    "        torch.cuda.synchronize()\n",
    "        times.append((time.perf_counter() - t0) * 1000)\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "\n",
    "def benchmark_onnx(onnx_path, warmup=30, runs=100, imgsz=640):\n",
    "    sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    dummy = np.random.rand(1, 3, imgsz, imgsz).astype(np.float32)\n",
    "    \n",
    "    for _ in range(warmup):\n",
    "        sess.run(None, {input_name: dummy})\n",
    "    \n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        t0 = time.perf_counter()\n",
    "        sess.run(None, {input_name: dummy})\n",
    "        times.append((time.perf_counter() - t0) * 1000)\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu26, gpu26_std = benchmark_gpu(yolo26_trained)\n",
    "gpu11, gpu11_std = benchmark_gpu(yolo11_trained)\n",
    "print(f\"GPU - YOLO26n: {gpu26:.2f}±{gpu26_std:.2f}ms, YOLO11n: {gpu11:.2f}±{gpu11_std:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "onnx26 = yolo26_trained.export(format='onnx', imgsz=CONFIG['imgsz'], simplify=True)\nonnx11 = yolo11_trained.export(format='onnx', imgsz=CONFIG['imgsz'], simplify=True)\n\nonnx26_size = os.path.getsize(onnx26) / 1e6\nonnx11_size = os.path.getsize(onnx11) / 1e6\nprint(f\"ONNX size - YOLO26n: {onnx26_size:.1f}MB, YOLO11n: {onnx11_size:.1f}MB\")\n\ncpu26, cpu26_std = benchmark_onnx(onnx26)\ncpu11, cpu11_std = benchmark_onnx(onnx11)\nprint(f\"CPU ONNX - YOLO26n: {cpu26:.2f}±{cpu26_std:.2f}ms, YOLO11n: {cpu11:.2f}±{cpu11_std:.2f}ms\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "speed_df = pd.DataFrame([\n    {'Model': 'YOLO26n', 'Device': 'GPU', 'Time_ms': gpu26, 'Std': gpu26_std},\n    {'Model': 'YOLO11n', 'Device': 'GPU', 'Time_ms': gpu11, 'Std': gpu11_std},\n    {'Model': 'YOLO26n', 'Device': 'CPU-ONNX', 'Time_ms': cpu26, 'Std': cpu26_std},\n    {'Model': 'YOLO11n', 'Device': 'CPU-ONNX', 'Time_ms': cpu11, 'Std': cpu11_std},\n])\n\nmodel_df = pd.DataFrame([\n    {'Model': 'YOLO26n', 'Params_M': params26/1e6, 'ONNX_MB': onnx26_size},\n    {'Model': 'YOLO11n', 'Params_M': params11/1e6, 'ONNX_MB': onnx11_size},\n])\n\ncpu_speedup = (1 - cpu26 / cpu11) * 100\nprint(f\"CPU Speedup: YOLO26 is {cpu_speedup:+.1f}% vs YOLO11 (claimed: +43%)\")\nprint(f\"\\nModel Size:\")\nprint(model_df.to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Evaluation by Object Size\n",
    "\n",
    "Testing ProgLoss + STAL claim for small object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom PIL import Image\n\nCLASSES = ['pedestrian', 'people', 'bicycle', 'car', 'van',\n           'truck', 'tricycle', 'awning-tricycle', 'bus', 'motor']\nDATA_PATH = Path('datasets/VisDrone')\n\n\ndef create_coco_gt(data_path):\n    images_dir = data_path / 'VisDrone2019-DET-val' / 'images'\n    labels_dir = data_path / 'VisDrone2019-DET-val' / 'labels'\n    \n    coco = {'images': [], 'annotations': [], 'categories': [\n        {'id': i, 'name': n} for i, n in enumerate(CLASSES)\n    ]}\n    \n    ann_id = 0\n    for img_id, img_path in enumerate(sorted(images_dir.glob('*.jpg'))):\n        with Image.open(img_path) as im:\n            w, h = im.size\n        coco['images'].append({'id': img_id, 'file_name': img_path.name, 'width': w, 'height': h})\n        \n        label_path = labels_dir / f\"{img_path.stem}.txt\"\n        if label_path.exists():\n            for line in open(label_path):\n                parts = line.strip().split()\n                if len(parts) >= 5:\n                    cls = int(parts[0])\n                    xc, yc, bw, bh = map(float, parts[1:5])\n                    xc, yc, bw, bh = xc*w, yc*h, bw*w, bh*h\n                    coco['annotations'].append({\n                        'id': ann_id, 'image_id': img_id, 'category_id': cls,\n                        'bbox': [xc-bw/2, yc-bh/2, bw, bh], 'area': bw*bh, 'iscrowd': 0\n                    })\n                    ann_id += 1\n    return coco\n\n\ndef get_predictions(model, data_path, device=0):\n    images_dir = data_path / 'VisDrone2019-DET-val' / 'images'\n    preds = []\n    for img_id, img_path in enumerate(sorted(images_dir.glob('*.jpg'))):\n        results = model.predict(str(img_path), device=device, verbose=False)[0]\n        if results.boxes is not None:\n            for box, conf, cls in zip(results.boxes.xyxy.cpu().numpy(),\n                                       results.boxes.conf.cpu().numpy(),\n                                       results.boxes.cls.cpu().numpy()):\n                x1, y1, x2, y2 = box\n                preds.append({\n                    'image_id': img_id, 'category_id': int(cls),\n                    'bbox': [float(x1), float(y1), float(x2-x1), float(y2-y1)],\n                    'score': float(conf)\n                })\n    return preds"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict = create_coco_gt(DATA_PATH)\n",
    "coco_gt = COCO()\n",
    "coco_gt.dataset = gt_dict\n",
    "coco_gt.createIndex()\n",
    "\n",
    "size_results = []\n",
    "for name, model in [('YOLO26n', yolo26_trained), ('YOLO11n', yolo11_trained)]:\n",
    "    preds = get_predictions(model, DATA_PATH)\n",
    "    coco_dt = coco_gt.loadRes(preds)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    size_results.append({\n",
    "        'Model': name,\n",
    "        'AP': coco_eval.stats[0],\n",
    "        'AP_small': coco_eval.stats[3],\n",
    "        'AP_medium': coco_eval.stats[4],\n",
    "        'AP_large': coco_eval.stats[5],\n",
    "    })\n",
    "\n",
    "size_df = pd.DataFrame(size_results)\n",
    "size_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 9))\n",
    "colors = {'YOLO26n': '#2ecc71', 'YOLO11n': '#3498db'}\n",
    "\n",
    "# mAP\n",
    "ax = axes[0, 0]\n",
    "x = np.arange(2)\n",
    "ax.bar(x - 0.15, metrics['mAP50'], 0.3, label='mAP50', color='#3498db')\n",
    "ax.bar(x + 0.15, metrics['mAP50-95'], 0.3, label='mAP50-95', color='#2ecc71')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics['Model'])\n",
    "ax.set_ylabel('mAP')\n",
    "ax.set_title('Overall Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "# GPU Speed\n",
    "ax = axes[0, 1]\n",
    "bars = ax.bar(['YOLO26n', 'YOLO11n'], [gpu26, gpu11], color=[colors['YOLO26n'], colors['YOLO11n']])\n",
    "ax.set_ylabel('Time (ms)')\n",
    "ax.set_title('GPU Inference (T4)')\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1f}', ha='center', va='bottom')\n",
    "\n",
    "# AP by Size\n",
    "ax = axes[1, 0]\n",
    "x = np.arange(3)\n",
    "ax.bar(x - 0.15, [size_df[size_df['Model']=='YOLO26n'][c].values[0] for c in ['AP_small', 'AP_medium', 'AP_large']], 0.3, label='YOLO26n', color=colors['YOLO26n'])\n",
    "ax.bar(x + 0.15, [size_df[size_df['Model']=='YOLO11n'][c].values[0] for c in ['AP_small', 'AP_medium', 'AP_large']], 0.3, label='YOLO11n', color=colors['YOLO11n'])\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Small', 'Medium', 'Large'])\n",
    "ax.set_ylabel('AP')\n",
    "ax.set_title('AP by Object Size')\n",
    "ax.legend()\n",
    "\n",
    "# CPU ONNX Speed\n",
    "ax = axes[1, 1]\n",
    "bars = ax.bar(['YOLO26n', 'YOLO11n'], [cpu26, cpu11], color=[colors['YOLO26n'], colors['YOLO11n']])\n",
    "ax.set_ylabel('Time (ms)')\n",
    "ax.set_title(f'CPU Inference ONNX ({cpu_speedup:+.0f}%)')\n",
    "for bar in bars:\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f'{bar.get_height():.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.suptitle('YOLO26 vs YOLO11 on VisDrone', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('benchmark_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "small_diff = size_df[size_df['Model']=='YOLO26n']['AP_small'].values[0] - size_df[size_df['Model']=='YOLO11n']['AP_small'].values[0]\n\nprint(\"=\"*60)\nprint(\"SUMMARY\")\nprint(\"=\"*60)\nprint(f\"\\nModel Size: YOLO26n={params26/1e6:.2f}M, YOLO11n={params11/1e6:.2f}M\")\nprint(f\"ONNX Size: YOLO26n={onnx26_size:.1f}MB, YOLO11n={onnx11_size:.1f}MB\")\nprint(f\"\\nAccuracy (mAP50): YOLO26n={metrics[metrics['Model']=='YOLO26n']['mAP50'].values[0]:.3f}, YOLO11n={metrics[metrics['Model']=='YOLO11n']['mAP50'].values[0]:.3f}\")\nprint(f\"Small Object AP: YOLO26n={size_df[size_df['Model']=='YOLO26n']['AP_small'].values[0]:.4f}, YOLO11n={size_df[size_df['Model']=='YOLO11n']['AP_small'].values[0]:.4f} ({small_diff:+.4f})\")\nprint(f\"\\nGPU Speed (T4): YOLO26n={gpu26:.2f}ms, YOLO11n={gpu11:.2f}ms\")\nprint(f\"CPU Speed (ONNX): YOLO26n={cpu26:.2f}ms, YOLO11n={cpu11:.2f}ms ({cpu_speedup:+.1f}%, claimed +43%)\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "metrics.to_csv('metrics.csv', index=False)\nspeed_df.to_csv('speed.csv', index=False)\nsize_df.to_csv('size_metrics.csv', index=False)\nmodel_df.to_csv('model_info.csv', index=False)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}